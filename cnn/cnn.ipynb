{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import sys\n",
    "dest = \"./images/test2/{0}\"\n",
    "\n",
    "def resizeImage(src):\n",
    "    files = glob.glob('./images/test/{0}/*'.format(src))\n",
    "    for file in files:\n",
    "        delim = \"/\"\n",
    "        name = file.split(delim)[-1]\n",
    "        name = file.split(\"\\\\\")[-1]\n",
    "        I = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        I = cv2.resize(I, (48, 48), interpolation = cv2.INTER_AREA)\n",
    "        cv2.imwrite(dest.format(src) + delim + name, I)\n",
    "resizeImage('angry')\n",
    "resizeImage('happy')\n",
    "resizeImage('neutral')\n",
    "resizeImage('sad')\n",
    "resizeImage('surprise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import sys\n",
    "import random\n",
    "dest1 = \"./images/jaffe/{0}/*\"\n",
    "dest2 = \"./images/other_dataset/{0}/*\"\n",
    "dest3 = \"./images/other_train/{0}\"\n",
    "dest4 = \"./images/other_validation/{0}\"\n",
    "dest5 = \"./images/test/{0}\"\n",
    "def copyImage(src, files, dest):\n",
    "    for file in files:\n",
    "        delim = \"/\"\n",
    "        name = file.split(delim)[-1]\n",
    "        name = file.split(\"\\\\\")[-1]\n",
    "        I = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        cv2.imwrite(dest.format(src) + delim + name, I)\n",
    "def divide_train_val_test(src):\n",
    "    files_ja = glob.glob(dest1.format(src))\n",
    "    files_oth = glob.glob(dest2.format(src))\n",
    "    random.shuffle(files_ja)\n",
    "    random.shuffle(files_oth)\n",
    "    train_ja = files_ja[int(len(files_ja) * .0) : int(len(files_ja) * .7)]\n",
    "    train_oth = files_oth[int(len(files_oth) * .0) : int(len(files_oth) * .7)]\n",
    "    val_ja = files_ja[int(len(files_ja) * .7) : int(len(files_ja) * .9)]\n",
    "    val_oth = files_oth[int(len(files_oth) * .7) : int(len(files_oth) * .9)]\n",
    "    test_ja = files_ja[int(len(files_ja) * .9) : int(len(files_ja) * 1.0)]\n",
    "    test_oth = files_oth[int(len(files_oth) * .9) : int(len(files_oth) * 1.0)]\n",
    "#    copyImage(src, train_ja, dest3)\n",
    "#    copyImage(src, train_oth, dest3)\n",
    "#    copyImage(src, val_ja, dest4)\n",
    "    copyImage(src, val_oth, dest4)\n",
    "#     copyImage(src, test_ja, dest5)\n",
    "#    copyImage(src, test_oth, dest5)\n",
    "divide_train_val_test('angry')\n",
    "divide_train_val_test('happy')\n",
    "divide_train_val_test('neutral')\n",
    "divide_train_val_test('sad')\n",
    "divide_train_val_test('surprise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24865 images belonging to 5 classes.\n",
      "Found 6104 images belonging to 5 classes.\n",
      "Epoch 1/1000\n",
      "4096/4096 [==============================] - 278s 68ms/step - loss: 1.4554 - acc: 0.3690 - val_loss: 1.1685 - val_acc: 0.5197\n",
      "Epoch 2/1000\n",
      "4096/4096 [==============================] - 272s 66ms/step - loss: 0.9977 - acc: 0.6114 - val_loss: 0.9091 - val_acc: 0.6494\n",
      "Epoch 3/1000\n",
      "4096/4096 [==============================] - 280s 68ms/step - loss: 0.8705 - acc: 0.6704 - val_loss: 0.8479 - val_acc: 0.6765\n",
      "Epoch 4/1000\n",
      "4096/4096 [==============================] - 284s 69ms/step - loss: 0.8061 - acc: 0.6979 - val_loss: 0.8284 - val_acc: 0.6859\n",
      "Epoch 5/1000\n",
      "4096/4096 [==============================] - 283s 69ms/step - loss: 0.7616 - acc: 0.7165 - val_loss: 0.8386 - val_acc: 0.6767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c4b44733c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_acc', mode='max', min_delta=0.004)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=10, min_lr=0.0001, verbose =1)\n",
    "model_check = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min')\n",
    "train_data_dir = 'images/train'\n",
    "validation_data_dir = 'images/validation'\n",
    "train_jaffe_dir = 'images/jaffe_train'\n",
    "validation_jaffe_dir = 'images/jaffe_validation'\n",
    "train_other_dir = 'images/other_train'\n",
    "validation_other_dir = 'images/other_validation'\n",
    "_dir = 'images/validation'\n",
    "datagen = ImageDataGenerator(rescale=1. / 255, rotation_range=45, width_shift_range=0.3, height_shift_range=0.1)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    directory=train_data_dir,\n",
    "    target_size=(48, 48),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=64,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "valid_generator = datagen.flow_from_directory(\n",
    "    directory=validation_data_dir,\n",
    "    target_size=(48, 48),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size = (3, 3), input_shape = (48, 48, 1), activation = 'relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size = (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, kernel_size = (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add((Dropout(0.4)))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size = (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, kernel_size = (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add((Dropout(0.5)))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size = (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512, kernel_size = (3, 3), activation = 'relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add((Dropout(0.5)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(5, activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=4096,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=1024,\n",
    "                    \n",
    "                    epochs=1000,\n",
    "                    callbacks= [model_check, earlystopping, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `evaluate_generator` call to the Keras 2 API: `evaluate_generator(generator=<keras_pre..., steps=832, use_multiprocessing=False)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83669641 0.68064904]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "bm = load_model('best_model.h5')\n",
    "valid_generator.batch_size = 1\n",
    "sum = np.array([0.0, 0.0])\n",
    "for i in range(10):\n",
    "    score = bm.evaluate_generator(generator=valid_generator, steps=832, pickle_safe=False)\n",
    "    sum += score\n",
    "\n",
    "print(sum / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "test_data_dir = 'images/test'\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    directory = test_data_dir,\n",
    "    target_size=(48, 48),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=139,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "test_generator.reset()\n",
    "pred = model.predict_generator(test_generator, steps= 1, verbose=1)\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "print(predicted_class_indices)\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "filenames=test_generator.filenames\n",
    "print(np.array(filenames).shape)\n",
    "print(np.array(predictions).shape)\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.to_csv(\"r.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "emotion_class = {0:'angry', 1:'happy', 2:'neutral', 3:'sad', 4:'surprise'}\n",
    "best_model = load_model('best_model.h5')\n",
    "\n",
    "def detect_emotion(face):\n",
    "    face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "    face = cv2.resize(face, (48, 48), interpolation = cv2.INTER_AREA)\n",
    "    face = face.reshape(1, 48, 48, 1)\n",
    "    face = face.astype(np.float32)\n",
    "    face = face / 255\n",
    "    emotion_index = best_model.predict_classes(face)\n",
    "\n",
    "    return emotion_class[emotion_index[0]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "FACE_DETECTOR = cv2.CascadeClassifier('./lbp/cascade.xml')\n",
    "CAP = cv2.VideoCapture(0)\n",
    "w = int(CAP.get(cv2.CAP_PROP_FRAME_WIDTH))  \n",
    "h = int(CAP.get(cv2.CAP_PROP_FRAME_HEIGHT)) \n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID') \n",
    "out = cv2.VideoWriter('out.avi',fourcc, 30.0, (w,h))\n",
    "\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "FONT_SCALE = 0.7\n",
    "FONT_COLOR = (100, 200, 100)\n",
    "LINE_TYPE = 2\n",
    "\n",
    "while 1:\n",
    "    RET, I = CAP.read()\n",
    "\n",
    "    G = cv2.cvtColor(I, cv2.COLOR_BGR2GRAY)\n",
    "    FACES = FACE_DETECTOR.detectMultiScale(G, 1.1, 3)\n",
    "\n",
    "    for (x, y, w, h) in FACES:\n",
    "        cv2.rectangle(I, (x - 10, y - 30), (x + w + 10, y + h + 30), (255, 100, 100), 3)\n",
    "        Face = I[y:y+h, x:x+h]\n",
    "        title = detect_emotion(Face)\n",
    "        cv2.putText(I, title,\n",
    "                    (x+10, y-5),\n",
    "                    FONT,\n",
    "                    FONT_SCALE,\n",
    "                    FONT_COLOR,\n",
    "                    LINE_TYPE)\n",
    "\n",
    "    cv2.imshow('I', I)\n",
    "    KEY = cv2.waitKey(60)\n",
    "    out.write(I)\n",
    "    if KEY == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "CAP.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
